{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "import torch\n",
    "import ast \n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains all results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the LSTM model\n",
    "(Her mangler vi dataen figurerne bliver lavet ud fra.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x=np.arange(1,num_epochs+1), y=train_loss_list, color='blue', label='Train');\n",
    "sns.lineplot(x=np.arange(1, num_epochs + 1), y=valid_loss_list, color='orange', label='Valid');\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"50epochs_cleaned.png\")\n",
    "\n",
    "# %%\n",
    "test_loss, test_acc, test_y_pred, test_y_true, test_y_pred_round = evaluate_model(model, test_iter, optimizer)\n",
    "test_y_pred_cat = torch.cat(test_y_pred)\n",
    "test_y_true_cat = torch.cat(test_y_true)\n",
    "test_auc = get_auroc(test_y_true_cat, test_y_pred_cat)\n",
    "test_spear = spearman(test_y_true_cat,test_y_pred_cat)\n",
    "print(f'''Test AUC score: {test_auc:.3f}''')\n",
    "print(test_spear)\n",
    "\n",
    "# Roc curve\n",
    "fpr, tpr, threshold = roc_curve(test_y_true_cat, test_y_pred_cat)\n",
    "\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('ROC LSTM')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\")\n",
    "plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig(\"50-epochs-roc-cleaned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for model\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "##### Load data for unbalanced dataset\n",
    "d_a = pd.read_csv(\"data/twitter_data/new_tweet_dataset_train.csv\")\n",
    "d_a = d_a.rename(columns={'tweet_text':'Tweet'})\n",
    "d_a['billed'] = d_a['Tweet'].apply(lambda x: 1 if 'http' in x else 0)\n",
    "d_a_ub = d_a[d_a['billed']==0]\n",
    "d_a_ub[[\"Tweet\",\"label\"]].to_csv(\"data/twitter_data/new_tweet_train.csv\",index=False)\n",
    "\n",
    "data_files = {\"train\": \"data/twitter_data/new_tweet_train.csv\"}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Tweet\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "##### Load data for balanced dataset (only for new prediction, old predictions are saved)\n",
    "# from datasets import load_from_disk\n",
    "# tokenized_balanced = load_from_disk(\"src/data/tokenized_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new predictions by loading pretrained model and tokenizer \n",
    "\n",
    "# Load Tokenizer and model for predicting\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "             \"src/bert_models/trained_bert_3\", num_labels=2)\n",
    "trainer = Trainer(model)\n",
    "\n",
    "#### Prediction unbalanced\n",
    "testset_unblanced = tokenized_datasets[\"Test\"]#.select(range(200))\n",
    "predictions_unb, labels_unb, _, = trainer.predict(testset_unblanced)\n",
    "\n",
    "#### Prediction balanced\n",
    "# testset_blanced   = tokenized_balanced[\"Test\"]#.select(range(200))\n",
    "# predictions_b, labels_b, _, = trainer.predict(testset_blanced)\n",
    "        # Load earlier prediction for balanced dataset\n",
    "predictions_b = np.load('src/data/PredictedTestData/PredictionTestData.npy')\n",
    "labels_b      = np.load('src/data/PredictedTestData/Labels.npy')\n",
    "\n",
    "#### evaluate - Accuracy\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "# print(metric.compute(predictions_b=np.argmax(predictions_b,-1), references=labels_b))\n",
    "\n",
    "#### Save predictions\n",
    "# np.save('src/data/PredictedTestData/PredictionTestData',predictions_b)\n",
    "# np.save('src/data/PredictedTestData/Labels',labels_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy and examples\n",
    "#accuarcy\n",
    "acc_unb = np.sum(np.argmax(predictions_unb,axis=-1)==labels_unb)/200\n",
    "acc_b   = np.sum(np.argmax(predictions_b,axis=-1)==labels_b)/200\n",
    "\n",
    "#examples\n",
    "print(testset_unblanced['Tweet'][:2], testset_unblanced['Tweet'][175],testset_unblanced['Tweet'][45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for balanced dataset\n",
    "exppred = np.exp(predictions_b)\n",
    "predsoft = exppred/np.sum(exppred)\n",
    "predsoft /= np.max(predsoft)\n",
    "ratio = np.c_[[(predsoft[:,1]>i) for i in np.linspace(0.01,0.95,1000)]]\n",
    "\n",
    "TP = np.sum((labels_b==ratio)[:,labels_b==1], 1)\n",
    "TN = np.sum((labels_b==ratio)[:,labels_b==0], 1)\n",
    "FP = np.sum((labels_b!=ratio)[:,labels_b==0], 1) \n",
    "FN = np.sum((labels_b!=ratio)[:,labels_b==1], 1)\n",
    "\n",
    "TPR = TP/(TP+FN) # Recall/sensitivity\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "# AUC score\n",
    "auc(FPR, TPR)\n",
    "\n",
    "# Visualization\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('ROC BERT')\n",
    "plt.plot(FPR, TPR)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig(\"50-epochs-roc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loss\n",
    "\n",
    "# load data from output file\n",
    "output = []\n",
    "for i in ['Output_14988963']:\n",
    "    with open(f'src/log/{i}.out') as f:\n",
    "        output.append(np.array(f.readlines())[1:])\n",
    "messagedict =  [list(map(ast.literal_eval,run)) for run in output]\n",
    "\n",
    "mapp = lambda x: [[epoch[x] for epoch in run if x in epoch] for run in messagedict]\n",
    "eval_loss=mapp('eval_loss');eval_accu=mapp('eval_accuracy');train_loss=mapp('loss') \n",
    "\n",
    "# visualize train and validation loss\n",
    "num_epochs = 10\n",
    "train_loss_ = np.array(train_loss[0])[np.linspace(0,len(train_loss[0])-1,10).astype(int)]\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x=np.arange(1,num_epochs+1), y=train_loss_, color='blue', label='Train');\n",
    "sns.lineplot(x=np.arange(1, num_epochs + 1), y=eval_loss[0], color='orange', label='Valid');\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"test.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HRnet_Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1dca15f1148ce851678aad6e1f99401e4ba5411c7555a736b6fd2e38fc8fb9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
